{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "colab-1"
      },
      "source": [
        "### üìò Video 4: Make AI Search the Web (LangChain for Beginners, Part 4)\n",
        "\n",
        "**Goal**: Let your AI search the web for up-to-date answers ‚Äî no API keys, all free.\n",
        "\n",
        "‚úÖ Uses DuckDuckGo (no API key)\n",
        "\n",
        "‚úÖ Combines search + local LLM\n",
        "\n",
        "‚úÖ Runs on free Colab GPU\n",
        "\n",
        "üåê Let's make your AI know what's happening *right now*!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "install-deps",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09f528c5-154b-4ace-de2e-e585cd560fd1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ddgs in /usr/local/lib/python3.12/dist-packages (9.6.0)\n",
            "Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.12/dist-packages (from ddgs) (8.3.0)\n",
            "Requirement already satisfied: primp>=0.15.0 in /usr/local/lib/python3.12/dist-packages (from ddgs) (0.15.0)\n",
            "Requirement already satisfied: lxml>=6.0.0 in /usr/local/lib/python3.12/dist-packages (from ddgs) (6.0.2)\n",
            "Requirement already satisfied: httpx>=0.28.1 in /usr/local/lib/python3.12/dist-packages (from httpx[brotli,http2,socks]>=0.28.1->ddgs) (0.28.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (0.16.0)\n",
            "Requirement already satisfied: brotli in /usr/local/lib/python3.12/dist-packages (from httpx[brotli,http2,socks]>=0.28.1->ddgs) (1.1.0)\n",
            "Requirement already satisfied: h2<5,>=3 in /usr/local/lib/python3.12/dist-packages (from httpx[brotli,http2,socks]>=0.28.1->ddgs) (4.3.0)\n",
            "Requirement already satisfied: socksio==1.* in /usr/local/lib/python3.12/dist-packages (from httpx[brotli,http2,socks]>=0.28.1->ddgs) (1.0.0)\n",
            "Requirement already satisfied: hyperframe<7,>=6.1 in /usr/local/lib/python3.12/dist-packages (from h2<5,>=3->httpx[brotli,http2,socks]>=0.28.1->ddgs) (6.1.0)\n",
            "Requirement already satisfied: hpack<5,>=4.1 in /usr/local/lib/python3.12/dist-packages (from h2<5,>=3->httpx[brotli,http2,socks]>=0.28.1->ddgs) (4.1.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (1.3.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (4.15.0)\n"
          ]
        }
      ],
      "source": [
        "# Install required libraries\n",
        "!pip install -q langchain-huggingface langchain-community duckduckgo-search transformers torch accelerate bitsandbytes\n",
        "!pip install -U ddgs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "why-web-search"
      },
      "source": [
        "### üåê Why Add Web Search?\n",
        "\n",
        "Local models like TinyLlama have **no knowledge after their training date**.\n",
        "\n",
        "To answer:\n",
        "- \"Who won the latest Eurovision?\"\n",
        "- \"What's NVIDIA's stock price today?\"\n",
        "\n",
        "‚Ä¶you need **real-time data**.\n",
        "\n",
        "üëâ This is how production AI systems stay current."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "load-model",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b9d5d53-82aa-47cc-880b-b262fc9dea0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Model loaded!\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
        "from langchain_huggingface import HuggingFacePipeline\n",
        "\n",
        "# Load model\n",
        "model_name = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    device_map=\"auto\",\n",
        "    torch_dtype=\"auto\",\n",
        "    trust_remote_code=True\n",
        ")\n",
        "\n",
        "# Create pipeline\n",
        "pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    max_new_tokens=100,\n",
        "    temperature=0.7,\n",
        "    do_sample=True\n",
        ")\n",
        "\n",
        "# Wrap with LangChain\n",
        "llm = HuggingFacePipeline(pipeline=pipe)\n",
        "\n",
        "print(\"‚úÖ Model loaded!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "add-search"
      },
      "source": [
        "### üîç Add Web Search Tool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "search-tool"
      },
      "outputs": [],
      "source": [
        "from langchain_community.utilities import DuckDuckGoSearchAPIWrapper\n",
        "from langchain.tools import Tool\n",
        "\n",
        "# Initialize search\n",
        "search = DuckDuckGoSearchAPIWrapper()\n",
        "\n",
        "# Define search tool\n",
        "search_tool = Tool(\n",
        "    name=\"web_search\",\n",
        "    description=\"Search the web for current information\",\n",
        "    func=lambda query: search.results(query, max_results=3)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ask-current-questions"
      },
      "source": [
        "### üß™ Ask Questions with Live Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "demo-search",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93054a76-5c74-4446-d19e-7d5e6b63556f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q: Who won the 2024 Eurovision Song Contest?\n",
            "üîç Searching: Who won the 2024 Eurovision Song Contest?\n",
            "A: The winner of the 2024 Eurovision Song Contest was Switzerland's \"The Code\" by Nemo, with a total of 591 points.\n",
            "\n",
            "Q: What is the capital of Japan?\n",
            "üîç Searching: What is the capital of Japan?\n",
            "A: The capital of Japan is Tokyo.\n"
          ]
        }
      ],
      "source": [
        "def answer_with_search(question):\n",
        "    print(f\"üîç Searching: {question}\")\n",
        "    results = search_tool.run(question)\n",
        "\n",
        "    # Format results\n",
        "    context = \"\\n\".join([f\"[{i+1}] {r['title']}: {r['snippet']}\" for i, r in enumerate(results)])\n",
        "\n",
        "    prompt = f\"<|im_start|>system\\nYou are a helpful assistant. Answer based only on the search results below. Be concise.\\n<|im_end|>\\n<|im_start|>user\\nSearch results:\\n{context}\\n\\nQuestion: {question}<|im_end|>\\n<|im_start|>assistant\\n\"\n",
        "    response = llm.invoke(prompt)\n",
        "    answer = response.replace(prompt, \"\").replace(\"<|im_start|>assistant\\n\", \"\").replace(\"<|im_end|>\", \"\").strip()\n",
        "    return answer\n",
        "\n",
        "# Try it\n",
        "q1 = \"Who won the 2024 Eurovision Song Contest?\"\n",
        "print(f\"Q: {q1}\")\n",
        "print(f\"A: {answer_with_search(q1)}\\n\")\n",
        "\n",
        "q2 = \"What is the capital of Japan?\"  # Simple fact\n",
        "print(f\"Q: {q2}\")\n",
        "print(f\"A: {answer_with_search(q2)}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Try it\n",
        "q3 = \"Where will the next soccer cup be held?\"\n",
        "print(f\"Q: {q3}\")\n",
        "print(f\"A: {answer_with_search(q3)}\\n\")\n",
        "\n",
        "q4 = \"What is an AI Agent?\"  # Simple fact\n",
        "print(f\"Q: {q4}\")\n",
        "print(f\"A: {answer_with_search(q4)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJP5QApO1CpG",
        "outputId": "10b3b4a9-147d-4694-cbaa-787311e51dac"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q: Where will the next soccer cup be held?\n",
            "üîç Searching: Where will the next soccer cup be held?\n",
            "A: The 2026 World Cup will be hosted by the United States, Canada, and Mexico.\n",
            "\n",
            "Q: What is an AI Agent?\n",
            "üîç Searching: What is an AI Agent?\n",
            "A: An AI Agent is a program or software designed to perform tasks without human intervention. It uses machine learning algorithms and artificial intelligence to analyze data and make decisions. AI agents can perform tasks such as personal assistants, chatbots, and self-driving cars. The search results below provide more information on AI agents, including their characteristics, benefits, and limitations.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "summary"
      },
      "source": [
        "### üéâ Summary\n",
        "\n",
        "In this notebook, you:\n",
        "\n",
        "‚úÖ Gave your AI **real-time knowledge**\n",
        "\n",
        "‚úÖ Used `DuckDuckGoSearchAPIWrapper` (no API key!)\n",
        "\n",
        "‚úÖ Built a search-augmented AI\n",
        "\n",
        "üí° This is **Retrieval-Augmented Generation (RAG) with live data** ‚Äî used in enterprise AI systems\n",
        "\n",
        "‚û°Ô∏è **Next: Make AI use tools ‚Äî become a true agent!**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "resources"
      },
      "source": [
        "### üîó Resources\n",
        "\n",
        "- [LangChain Tools Docs](https://python.langchain.com/docs/modules/agents/tools/)\n",
        "- [DuckDuckGo Search Wrapper](https://api.python.langchain.com/en/latest/utilities/langchain_community.utilities.duckduckgo_search.DuckDuckGoSearchAPIWrapper.html)\n",
        "- [Author: Doug Ortiz](https://www.linkedin.com/in/doug-ortiz-illustris/)\n",
        "- [YouTube Channel: @techbits-do](https://www.youtube.com/@techbits-do)\n",
        "- [Illustris.org](https://www.illustris.org)"
      ]
    }
  ]
}